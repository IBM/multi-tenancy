{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Multi tenancy - architecture and projects \u00b6 ------------------ UNDER CONSTRUCTION ------------------ Multi-tenancy projects \u00b6 Serverless OpenShift Satellite Target architecture serverless : \u00b6 One frontend per tenant, one business logic per tenant. This is a simplified diagram containing the used elements and dependencies. Just a single tenant. This is a simplified diagram containing the used elements and dependencies. Technology Used \u00b6 The example ecommerce mircorservices application is build on following technologies/services/tools/frameworks . Microservices architecture OpenID Connect Jakarta EE MicroProfile IBM Cloud Code Engine Postgres AppID Toolchain Quarkus Vue.js NGINX git 2.24.1 or higher yarn 1.22.4 or higher Node.js v14.6.0 or higher Apache Maven 3.6.3 Quay Tekton Bash jq sed grep","title":"Architecture and projects"},{"location":"#multi-tenancy-architecture-and-projects","text":"------------------ UNDER CONSTRUCTION ------------------","title":"Multi tenancy - architecture and projects"},{"location":"#multi-tenancy-projects","text":"Serverless OpenShift Satellite","title":"Multi-tenancy projects"},{"location":"#target-architecture-serverless","text":"One frontend per tenant, one business logic per tenant. This is a simplified diagram containing the used elements and dependencies. Just a single tenant. This is a simplified diagram containing the used elements and dependencies.","title":"Target architecture serverless:"},{"location":"#technology-used","text":"The example ecommerce mircorservices application is build on following technologies/services/tools/frameworks . Microservices architecture OpenID Connect Jakarta EE MicroProfile IBM Cloud Code Engine Postgres AppID Toolchain Quarkus Vue.js NGINX git 2.24.1 or higher yarn 1.22.4 or higher Node.js v14.6.0 or higher Apache Maven 3.6.3 Quay Tekton Bash jq sed grep","title":"Technology Used"},{"location":"TBD/","text":"TBD \u00b6","title":"5. TBD"},{"location":"TBD/#tbd","text":"","title":"TBD"},{"location":"backend-service-container/","text":"Backend Microservice Container \u00b6 Quarkus is a great way to build microservices with Java. It doesn't require a lot of memory, it starts very fast, it comes with very popular Java libraries and has a big community. When creating new Quarkus projects via the CLI, Maven or the UI, various Dockerfiles are created automatically. In this project the generated Dockerfile is used which is based on ubi8/ubi-minimal and uses the Hotspot JVM. Check out the Dockerfile . Description: The image has not been optimized, for example by using OpenJ9. The generated Dockerfile is roughly from mid 2020 and uses old versions. As a result the IBM vulnerability scans show errors which need to be fixed by using newer versions. The image doesn't use root users so that it can be run on OpenShift. The Dockerfile uses two stages. The first stage uses Maven to build the application. This stage should be updated as well. The image listens to port 8081. The image can be configured with various environment variables to access Postgres and AppID. See the deployment.yaml for details. The Postgres certificate is not copied on the image for security reasons. Instead it is copied on the container directory '/cloud-postgres-cert' via a bash script .","title":"Backend service container"},{"location":"backend-service-container/#backend-microservice-container","text":"Quarkus is a great way to build microservices with Java. It doesn't require a lot of memory, it starts very fast, it comes with very popular Java libraries and has a big community. When creating new Quarkus projects via the CLI, Maven or the UI, various Dockerfiles are created automatically. In this project the generated Dockerfile is used which is based on ubi8/ubi-minimal and uses the Hotspot JVM. Check out the Dockerfile . Description: The image has not been optimized, for example by using OpenJ9. The generated Dockerfile is roughly from mid 2020 and uses old versions. As a result the IBM vulnerability scans show errors which need to be fixed by using newer versions. The image doesn't use root users so that it can be run on OpenShift. The Dockerfile uses two stages. The first stage uses Maven to build the application. This stage should be updated as well. The image listens to port 8081. The image can be configured with various environment variables to access Postgres and AppID. See the deployment.yaml for details. The Postgres certificate is not copied on the image for security reasons. Instead it is copied on the container directory '/cloud-postgres-cert' via a bash script .","title":"Backend Microservice Container"},{"location":"backend-service-impl/","text":"Implementation of the Backend Microservice \u00b6 You can find the implementation of the backend service in the multi-tenancy-backend repo. The service has been developed with Quarkus: Dependencies managed via Maven REST Endpoints via Rest Easy http://localhost:8081/category is protected and will return a response code '401' not authorized http://localhost:8081/category/2/products is not protected and will return data from Postgres Authentication Implementation Persistence via Hibernate The backend service uses different databases for different tenants as well as different AppID service instances The Postgres and AppID instances need to be created first and they need to be configured (e.g. test users, sample data) Configuration of Postgres and AppID Check out these local development instructions how to develop, run and debug the backend and frontend services locally The application runs on port 8081 CORS is enabled","title":"Backend service impl"},{"location":"backend-service-impl/#implementation-of-the-backend-microservice","text":"You can find the implementation of the backend service in the multi-tenancy-backend repo. The service has been developed with Quarkus: Dependencies managed via Maven REST Endpoints via Rest Easy http://localhost:8081/category is protected and will return a response code '401' not authorized http://localhost:8081/category/2/products is not protected and will return data from Postgres Authentication Implementation Persistence via Hibernate The backend service uses different databases for different tenants as well as different AppID service instances The Postgres and AppID instances need to be created first and they need to be configured (e.g. test users, sample data) Configuration of Postgres and AppID Check out these local development instructions how to develop, run and debug the backend and frontend services locally The application runs on port 8081 CORS is enabled","title":"Implementation of the Backend Microservice"},{"location":"cd-pipeline/","text":"IBM DevSecOps Reference Implementation - CD Pipeline \u00b6 The CD pipeline deploys the application to the production environments of specific tenants. For compliance reasons it needs to be triggered manually and the promotion pipeline needs to be run before. Step 1 Trigger manually the CD pipeline for certain tenant. Step 2 The CI pipeline reads the configuration. Either Kubernetes or OpenShift can be used; in a shared cluster or isolated clusters for tentants. The configuration is read: Step 3 Repos are cloned: Step 4 The delta is calculated, since only changes are deployed. Additionally security checks are performed again. Step 5 The actual deployment is performed. Step 6 The application can be opened. Step 7 Data is collected.","title":"Cd pipeline"},{"location":"cd-pipeline/#ibm-devsecops-reference-implementation-cd-pipeline","text":"The CD pipeline deploys the application to the production environments of specific tenants. For compliance reasons it needs to be triggered manually and the promotion pipeline needs to be run before. Step 1 Trigger manually the CD pipeline for certain tenant. Step 2 The CI pipeline reads the configuration. Either Kubernetes or OpenShift can be used; in a shared cluster or isolated clusters for tentants. The configuration is read: Step 3 Repos are cloned: Step 4 The delta is calculated, since only changes are deployed. Additionally security checks are performed again. Step 5 The actual deployment is performed. Step 6 The application can be opened. Step 7 Data is collected.","title":"IBM DevSecOps Reference Implementation - CD Pipeline"},{"location":"cd-pull-request/","text":"IBM DevSecOps Reference Implementation - CD Pull Request \u00b6 In order to deploy a new version for a specific tenant, a pull request (which is the same as a merge request in GitLab) has to be created and merged. The pull request merges the latest version in the main branch of the inventory to the tenant specific branches in the inventory. Step 1 Trigger manually the CD promotion trigger pipeline. Step 2 A pull request is created. Step 3 In the pull request the priority and assignee has to be defined. After this it can be saved and merged. Next After the pull request has been merged, the actual CD pipeline can be triggered.","title":"Cd pull request"},{"location":"cd-pull-request/#ibm-devsecops-reference-implementation-cd-pull-request","text":"In order to deploy a new version for a specific tenant, a pull request (which is the same as a merge request in GitLab) has to be created and merged. The pull request merges the latest version in the main branch of the inventory to the tenant specific branches in the inventory. Step 1 Trigger manually the CD promotion trigger pipeline. Step 2 A pull request is created. Step 3 In the pull request the priority and assignee has to be defined. After this it can be saved and merged. Next After the pull request has been merged, the actual CD pipeline can be triggered.","title":"IBM DevSecOps Reference Implementation - CD Pull Request"},{"location":"ci-pipeline/","text":"IBM DevSecOps Reference Implementation - CI Pipeline \u00b6 The CI pipelines (one for backend, one for frontend) build and push the images and run various security and code tests. Only if all checks pass, the application can be deployed to production via the CD pipelines. This assures that new versions can be deployed at any time based on business (not technical) decisions. Overview: Build and push images Run various security checks (secret detection, image vulnerabilities, compliance) Run various code tests (unit tests, acceptance tests) Deploy services to integration/testing Kubernetes namespaces or OpenShift projects Step 1 The CI pipeline is triggered automatically after the pull request has been merged. Step 2 The CI pipeline reads the configuration. Step 3 The image is built and pushed. Step 4 The backend container is deployed to an integration/testing Kubernetes namespace or OpenShift project. Step 5 The status can be monitored in IBM DevOps Insights. Step 6 The latest successful version is stored in the inventory repo. Step 7 Evidence is collected in the evidence repo Step 8 If the pipeline run has been successful, no issues are created in the compliance issues repo. Next After a successful run of the CI pipeline, the CD pipeline can be run.","title":"Ci pipeline"},{"location":"ci-pipeline/#ibm-devsecops-reference-implementation-ci-pipeline","text":"The CI pipelines (one for backend, one for frontend) build and push the images and run various security and code tests. Only if all checks pass, the application can be deployed to production via the CD pipelines. This assures that new versions can be deployed at any time based on business (not technical) decisions. Overview: Build and push images Run various security checks (secret detection, image vulnerabilities, compliance) Run various code tests (unit tests, acceptance tests) Deploy services to integration/testing Kubernetes namespaces or OpenShift projects Step 1 The CI pipeline is triggered automatically after the pull request has been merged. Step 2 The CI pipeline reads the configuration. Step 3 The image is built and pushed. Step 4 The backend container is deployed to an integration/testing Kubernetes namespace or OpenShift project. Step 5 The status can be monitored in IBM DevOps Insights. Step 6 The latest successful version is stored in the inventory repo. Step 7 Evidence is collected in the evidence repo Step 8 If the pipeline run has been successful, no issues are created in the compliance issues repo. Next After a successful run of the CI pipeline, the CD pipeline can be run.","title":"IBM DevSecOps Reference Implementation - CI Pipeline"},{"location":"ci-pull-request/","text":"IBM DevSecOps Reference Implementation - CI Pull Request \u00b6 Before developers can push their code into 'main', security checks need to pass and approvals need to be done first. Step 1 A developer creates a new version of README.md in the backend repo. The change is done in a developer branch. Step 2 The developer creates a pull request. Step 3 Before the pull request can be merged, security checks are performed via the 'backend pr-pipeline'. Step 4 After the security checks have passed, an approval from a second developer is required. Step 5 The second developer approves the pull request. Step 6 The pull request can now be merged. Next When the pull request has been merged, it triggers the CI pipeline .","title":"Ci pull request"},{"location":"ci-pull-request/#ibm-devsecops-reference-implementation-ci-pull-request","text":"Before developers can push their code into 'main', security checks need to pass and approvals need to be done first. Step 1 A developer creates a new version of README.md in the backend repo. The change is done in a developer branch. Step 2 The developer creates a pull request. Step 3 Before the pull request can be merged, security checks are performed via the 'backend pr-pipeline'. Step 4 After the security checks have passed, an approval from a second developer is required. Step 5 The second developer approves the pull request. Step 6 The pull request can now be merged. Next When the pull request has been merged, it triggers the CI pipeline .","title":"IBM DevSecOps Reference Implementation - CI Pull Request"},{"location":"code-engine-billing/","text":"Code Engine Billing \u00b6 ------------------ UNDER CONSTRUCTION ------------------ In this section we will explain the simplicity of billing when using Code Engine . As each tenant will be deployed as an individual Code Engine application, we will demonstrate how standard IBM Cloud tools can be used to determine per-tenant costs. Each tenant will have their own service instances for Postgres and AppId, so we will show how standard IBM Cloud billing can be used to see costs per service instance (or resource group, if we decide to organise the services in this way).","title":"Code engine billing"},{"location":"code-engine-billing/#code-engine-billing","text":"------------------ UNDER CONSTRUCTION ------------------ In this section we will explain the simplicity of billing when using Code Engine . As each tenant will be deployed as an individual Code Engine application, we will demonstrate how standard IBM Cloud tools can be used to determine per-tenant costs. Each tenant will have their own service instances for Postgres and AppId, so we will show how standard IBM Cloud billing can be used to see costs per service instance (or resource group, if we decide to organise the services in this way).","title":"Code Engine Billing"},{"location":"create_ibmcloud_account/","text":"Lab 1: Create IBM Cloud Account \u00b6 ------------------ UNDER CONSTRUCTION ------------------ Step 1: Create a PayAsYouGo IBM Cloud Account \u00b6 Open this link and follow the guided steps. Code Engine has a free tier per month and we expect, if you haven't used that free tier in current month, you can execute the workshop without creating any additional costs. Here you find the actual Code Engine pricing .","title":"1. Create an IBM Cloud account"},{"location":"create_ibmcloud_account/#lab-1-create-ibm-cloud-account","text":"------------------ UNDER CONSTRUCTION ------------------","title":"Lab 1: Create IBM Cloud Account"},{"location":"create_ibmcloud_account/#step-1-create-a-payasyougo-ibm-cloud-account","text":"Open this link and follow the guided steps. Code Engine has a free tier per month and we expect, if you haven't used that free tier in current month, you can execute the workshop without creating any additional costs. Here you find the actual Code Engine pricing .","title":"Step 1: Create a PayAsYouGo IBM Cloud Account"},{"location":"devsecops-overview/","text":"IBM DevSecOps Reference Implementation \u00b6 IBM uses internally a common practice and process how to implement DevSecOps. This process has been published so that IBM clients, partners and developers can use it too. See DevSecOps Reference Implementation for Audit-Ready Compliance for details. This project leverages the DevSecOps reference architecture to deploy the backend and frontend containers to Kubernetes and OpenShift on the IBM Cloud. There is IBM Cloud documentation that describes how to set up the CI and CD toolchains. The documentation below adopts this information for the multi-tenancy sample application. Overview \u00b6 There are six steps to deploy the SaaS sample application. CI backend pull request: Get approval to merge backend code changes into main CI backend pipeline: Pipeline to build backend image and deploy it to a staging environment for testing CI frontend pull request: Get approval to merge frontend code changes into main CI frontend pipeline: Pipeline to build frontend image and deploy it to a staging environment for testing CD pull request: Pull request to deploy main for a specific tenant to production CD pipeline: After approval deploy backend and frontend for a specific tenant to production Check out the following documents for details: CI pull request related to (1) and (3) CI pipeline related to (2) and (4) CD pull request related to (5) CD pipeline related to (6) Toolchains \u00b6 There are three toolchains: CI for backend CI for frontend CD Repos \u00b6 These three repos contain the code of the microservices and the toolchains (on github.com): multi-tenancy multi-tenancy-backend multi-tenancy-frontend The following repos contain state information and are shared by the three toolchains (on IBM Cloud GitLab): inventory complicance change management compliance issues evidence The following repo contains the code for the 'out-of-the-box' security checks (on IBM Cloud GitLab): compliance pipelines","title":"Devsecops overview"},{"location":"devsecops-overview/#ibm-devsecops-reference-implementation","text":"IBM uses internally a common practice and process how to implement DevSecOps. This process has been published so that IBM clients, partners and developers can use it too. See DevSecOps Reference Implementation for Audit-Ready Compliance for details. This project leverages the DevSecOps reference architecture to deploy the backend and frontend containers to Kubernetes and OpenShift on the IBM Cloud. There is IBM Cloud documentation that describes how to set up the CI and CD toolchains. The documentation below adopts this information for the multi-tenancy sample application.","title":"IBM DevSecOps Reference Implementation"},{"location":"devsecops-overview/#overview","text":"There are six steps to deploy the SaaS sample application. CI backend pull request: Get approval to merge backend code changes into main CI backend pipeline: Pipeline to build backend image and deploy it to a staging environment for testing CI frontend pull request: Get approval to merge frontend code changes into main CI frontend pipeline: Pipeline to build frontend image and deploy it to a staging environment for testing CD pull request: Pull request to deploy main for a specific tenant to production CD pipeline: After approval deploy backend and frontend for a specific tenant to production Check out the following documents for details: CI pull request related to (1) and (3) CI pipeline related to (2) and (4) CD pull request related to (5) CD pipeline related to (6)","title":"Overview"},{"location":"devsecops-overview/#toolchains","text":"There are three toolchains: CI for backend CI for frontend CD","title":"Toolchains"},{"location":"devsecops-overview/#repos","text":"These three repos contain the code of the microservices and the toolchains (on github.com): multi-tenancy multi-tenancy-backend multi-tenancy-frontend The following repos contain state information and are shared by the three toolchains (on IBM Cloud GitLab): inventory complicance change management compliance issues evidence The following repo contains the code for the 'out-of-the-box' security checks (on IBM Cloud GitLab): compliance pipelines","title":"Repos"},{"location":"getting-started/","text":"Getting Started \u00b6 The initial setup is only for the serverless part in Code Engine, with the objective to provide you an initial understanding of the application and providing a working environment with the example application and it components. The image shows simplified what we are doing during the Getting Started . Step 1: Clone the repositories \u00b6 $ git clone https://github.com/IBM/multi-tenancy $ git clone https://github.com/IBM/multi-tenancy-backend $ git clone https://github.com/IBM/multi-tenancy-frontend && cd multi-tenancy $ ROOT_FOLDER = $( pwd ) Step 2 : Verify the prerequisites for running the installation \u00b6 $ cd $ROOT_FOLDER /installapp $ sh ./ce-check-prerequisites.sh The script stops when it notices any prerequisite is missing. Example output: Check prereqisites 1 . Verify grep - Grep is installed: grep ( BSD grep, GNU compatible ) 2 .6.0-FreeBSD ! 2 . Verify awk - AWK is installed: awk version 20200816 ! 3 . Verify cURL - cURL is installed: curl 7 .77.0 ( x86_64-apple-darwin21.0 ) libcurl/7.77.0 ( SecureTransport ) LibreSSL/2.8.3 zlib/1.2.11 nghttp2/1.42.0 Release-Date: 2021 -05-26 Protocols: dict file ftp ftps gopher gophers http https imap imaps ldap ldaps mqtt pop3 pop3s rtsp smb smbs smtp smtps telnet tftp Features: alt-svc AsynchDNS GSS-API HSTS HTTP2 HTTPS-proxy IPv6 Kerberos Largefile libz MultiSSL NTLM NTLM_WB SPNEGO SSL UnixSockets ! 4 . Verify jq - JQ is installed: jq-1.6 ! 5 . Verify libpq ( psql ) - libpq ( psql ) is installed: psql ( PostgreSQL ) 14 .0 ! 6 . Verify Docker - Docker is installed: Docker version 20 .10.11, build dea9396 ! 7 . Verify ibmcloud cli - IBM Cloud CLI is installed: ibmcloud version 2 .3.0+26fbf88-2021-12-09T18:02:50+00:00 ! 8 . Verify ibmcloud plugin cloud-databases - IBM Cloud Plugin 'cloud-databases' is installed: cloud-databases ! 9 . Verify ibmcloud plugin code-engine - IBM Cloud Plugin 'code-engine' is installed: code-engine [ ce ] ! 10 . Verify ibmcloud plugin container-registry - IBM Cloud Plugin 'container-registry' is installed: container-registry ! Success! All prerequisites verified! You need the following tools installed locally to run the script above: ibmcloud cli ibmcloud plugin code-engine ibmcloud plugin cloud-databases ibmcloud plugin container-registry Docker sed jq grep libpq (psql) cURL AWK Step 3: Define the configuration for the tenants you want to install \u00b6 Define the global configuration in global.json . It includes IBM Cloud settings such as region and resource group, container registry information and image information . Additionally define the same global configuration in tenants-config . Note that this step will not be necessary sometime soon. For each tenant define tenant-specific configuration in the folder 'configuration/tenants'. That configuration contains for example App ID information . Postgres database information , application instance information , and Code Engine information . Here you find an example configuration tenant-a.json . Additionally define the same configuration in tenants-config . Note that this step will not be necessary sometime soon. Step 4: Configure IBM Cloud Container Registry Namespace and Code Engine project names \u00b6 The values for the names of the IBM Cloud Container Registry Namespace and the IBM Cloud Code Engine project must unique in IBM Cloud for a region! To avoid problems during running the setup, please configure these name to your needs. Configure your IBM Cloud Container Registry Namespace name In the global.json file you need to change the value for the IBM Cloud Container Registry Namespace name to something like multi-tenancy-example-mypostfix . \"REGISTRY\" : { \"URL\" : \"de.icr.io\" , \"NAMESPACE\" : \"multi-tenancy-example-[YOUR_POSTFIX]\" , \"SECRET_NAME\" : \"multi.tenancy.cr.sec\" , \"TAG\" : \"v2\" }, Configure your Code Engine project names for the two tenants In the tenant-a.json files you need to change the value for the Code Engine project to something like multi-tenancy-example-mypostfix . tenant-a.json : multi-tenancy-serverless-a-mypostfix \"CODE_ENGINE\" : { \"PROJECT_NAME\" : \"multi-tenancy-serverless-a-[YOUR_POSTFIX]\" } tenant-b.json : multi-tenancy-serverless-a-mypostfix \"CODE_ENGINE\" : { \"PROJECT_NAME\" : \"multi-tenancy-serverless-b-[YOUR_POSTFIX]\" } Step 5: Start the installation \u00b6 To create all components for the two sample tenants configurations, run the following commands: $ cd $ROOT_FOLDER /installapp $ ibmcloud login --sso $ sh ./ce-create-two-tenancies.sh The script takes roughly 30 minutes. You will be asked to review some configurations and press enter to move forward in some steps. The script will stop in some situations when it discovers a problem during the setup. After this the URL of the frontend applications will be displayed. For both tenants the following test user can be used to log in: User: thomas@example.com. Password: thomas4appid Step 6: Understand the details of the initial installation bash scripts \u00b6 We use three bash scripts for the initial installation. The following diagram shows the simplified dependencies of these bash scripts used to create two tenants of the example application on IBM Cloud in Code Engine. The scripts creating two tenants: Two Code Engine projects with two applications one frontend and one backend. Two App ID instance to provide a basic authentication and authorization for the two tenants. Two Postgres databases for the two tenants. The table contains the script and the responsibility of the scripts. Script Responsibility ce-create-two-tenancies.sh Build the container images for the frontend and backend, therefor it invokes the bash script ce-build-images-ibm-docker.sh and uploads the images to the IBM Cloud container registry. It also starts the creation of the tenant application instance, therefor it invokes the bash script ce-install-application.sh twice. ce-build-images-ibm-docker.sh Creates two container images based on the given parameters for the backend and frontend image names. ce-install-application.sh Creates and configures a Code Engine project . The configuration of the Code Engine project includes the creation of the application , the IBM Cloud Container Registry access therefor it also creates a IBM Cloud API and it creates the secrets for the needed parameter for the running applications. It creates an IBM Cloud App ID instance and configures this instance that includes the application , redirects , login layout , scope , role and user . It also creates an IBM Cloud Postgres database instance and creates the needed example data with tables inside the database. Step 7: Verify the setup by using following url https://cloud.ibm.com/resources \u00b6 In resource list of the IBM Cloud UI, insert as filter for name the value multi . Now you should see following in your resource list: Step 8: Open App ID instance for tenant a and inspect the configuration \u00b6 Open following URL https://cloud.ibm.com/resources Step 9: Open Code Engine project for tenant a and inspect the project \u00b6 Open following link in a browser: https://cloud.ibm.com/codeengine/projects Step 10: Open the frontend application for tenant a in the Code Engine project \u00b6 Step 11: Click on URL and log on to the frontend application using username thomas@example.com and password thomas4appid \u00b6 Step 12: Clean-up \u00b6 The clean-up reuses the configuration json files you defined for the setup/installatation. To delete all created resource you execute following commands: $ cd $ROOT_FOLDER /installapp $ ibmcloud login --sso $ sh ./ce-clean-up-two-tenancies.sh The table contains the script and the responsibility of the scripts. Script Responsibility ce-clean-up-two-tenancies.sh It starts the clean-up for the tenant application instances, therefor it invokes the bash script ce-clean-up.sh twice with the json configuration files as parameters. ce-clean-up.sh Deletes all created resouce for the two tenants.","title":"Getting Started"},{"location":"getting-started/#getting-started","text":"The initial setup is only for the serverless part in Code Engine, with the objective to provide you an initial understanding of the application and providing a working environment with the example application and it components. The image shows simplified what we are doing during the Getting Started .","title":"Getting Started"},{"location":"getting-started/#step-1-clone-the-repositories","text":"$ git clone https://github.com/IBM/multi-tenancy $ git clone https://github.com/IBM/multi-tenancy-backend $ git clone https://github.com/IBM/multi-tenancy-frontend && cd multi-tenancy $ ROOT_FOLDER = $( pwd )","title":"Step 1: Clone the repositories"},{"location":"getting-started/#step-2-verify-the-prerequisites-for-running-the-installation","text":"$ cd $ROOT_FOLDER /installapp $ sh ./ce-check-prerequisites.sh The script stops when it notices any prerequisite is missing. Example output: Check prereqisites 1 . Verify grep - Grep is installed: grep ( BSD grep, GNU compatible ) 2 .6.0-FreeBSD ! 2 . Verify awk - AWK is installed: awk version 20200816 ! 3 . Verify cURL - cURL is installed: curl 7 .77.0 ( x86_64-apple-darwin21.0 ) libcurl/7.77.0 ( SecureTransport ) LibreSSL/2.8.3 zlib/1.2.11 nghttp2/1.42.0 Release-Date: 2021 -05-26 Protocols: dict file ftp ftps gopher gophers http https imap imaps ldap ldaps mqtt pop3 pop3s rtsp smb smbs smtp smtps telnet tftp Features: alt-svc AsynchDNS GSS-API HSTS HTTP2 HTTPS-proxy IPv6 Kerberos Largefile libz MultiSSL NTLM NTLM_WB SPNEGO SSL UnixSockets ! 4 . Verify jq - JQ is installed: jq-1.6 ! 5 . Verify libpq ( psql ) - libpq ( psql ) is installed: psql ( PostgreSQL ) 14 .0 ! 6 . Verify Docker - Docker is installed: Docker version 20 .10.11, build dea9396 ! 7 . Verify ibmcloud cli - IBM Cloud CLI is installed: ibmcloud version 2 .3.0+26fbf88-2021-12-09T18:02:50+00:00 ! 8 . Verify ibmcloud plugin cloud-databases - IBM Cloud Plugin 'cloud-databases' is installed: cloud-databases ! 9 . Verify ibmcloud plugin code-engine - IBM Cloud Plugin 'code-engine' is installed: code-engine [ ce ] ! 10 . Verify ibmcloud plugin container-registry - IBM Cloud Plugin 'container-registry' is installed: container-registry ! Success! All prerequisites verified! You need the following tools installed locally to run the script above: ibmcloud cli ibmcloud plugin code-engine ibmcloud plugin cloud-databases ibmcloud plugin container-registry Docker sed jq grep libpq (psql) cURL AWK","title":"Step 2 : Verify the prerequisites for running the installation"},{"location":"getting-started/#step-3-define-the-configuration-for-the-tenants-you-want-to-install","text":"Define the global configuration in global.json . It includes IBM Cloud settings such as region and resource group, container registry information and image information . Additionally define the same global configuration in tenants-config . Note that this step will not be necessary sometime soon. For each tenant define tenant-specific configuration in the folder 'configuration/tenants'. That configuration contains for example App ID information . Postgres database information , application instance information , and Code Engine information . Here you find an example configuration tenant-a.json . Additionally define the same configuration in tenants-config . Note that this step will not be necessary sometime soon.","title":"Step 3: Define the configuration for the tenants you want to install"},{"location":"getting-started/#step-4-configure-ibm-cloud-container-registry-namespace-and-code-engine-project-names","text":"The values for the names of the IBM Cloud Container Registry Namespace and the IBM Cloud Code Engine project must unique in IBM Cloud for a region! To avoid problems during running the setup, please configure these name to your needs. Configure your IBM Cloud Container Registry Namespace name In the global.json file you need to change the value for the IBM Cloud Container Registry Namespace name to something like multi-tenancy-example-mypostfix . \"REGISTRY\" : { \"URL\" : \"de.icr.io\" , \"NAMESPACE\" : \"multi-tenancy-example-[YOUR_POSTFIX]\" , \"SECRET_NAME\" : \"multi.tenancy.cr.sec\" , \"TAG\" : \"v2\" }, Configure your Code Engine project names for the two tenants In the tenant-a.json files you need to change the value for the Code Engine project to something like multi-tenancy-example-mypostfix . tenant-a.json : multi-tenancy-serverless-a-mypostfix \"CODE_ENGINE\" : { \"PROJECT_NAME\" : \"multi-tenancy-serverless-a-[YOUR_POSTFIX]\" } tenant-b.json : multi-tenancy-serverless-a-mypostfix \"CODE_ENGINE\" : { \"PROJECT_NAME\" : \"multi-tenancy-serverless-b-[YOUR_POSTFIX]\" }","title":"Step 4: Configure IBM Cloud Container Registry Namespace and Code Engine project names"},{"location":"getting-started/#step-5-start-the-installation","text":"To create all components for the two sample tenants configurations, run the following commands: $ cd $ROOT_FOLDER /installapp $ ibmcloud login --sso $ sh ./ce-create-two-tenancies.sh The script takes roughly 30 minutes. You will be asked to review some configurations and press enter to move forward in some steps. The script will stop in some situations when it discovers a problem during the setup. After this the URL of the frontend applications will be displayed. For both tenants the following test user can be used to log in: User: thomas@example.com. Password: thomas4appid","title":"Step 5: Start the installation"},{"location":"getting-started/#step-6-understand-the-details-of-the-initial-installation-bash-scripts","text":"We use three bash scripts for the initial installation. The following diagram shows the simplified dependencies of these bash scripts used to create two tenants of the example application on IBM Cloud in Code Engine. The scripts creating two tenants: Two Code Engine projects with two applications one frontend and one backend. Two App ID instance to provide a basic authentication and authorization for the two tenants. Two Postgres databases for the two tenants. The table contains the script and the responsibility of the scripts. Script Responsibility ce-create-two-tenancies.sh Build the container images for the frontend and backend, therefor it invokes the bash script ce-build-images-ibm-docker.sh and uploads the images to the IBM Cloud container registry. It also starts the creation of the tenant application instance, therefor it invokes the bash script ce-install-application.sh twice. ce-build-images-ibm-docker.sh Creates two container images based on the given parameters for the backend and frontend image names. ce-install-application.sh Creates and configures a Code Engine project . The configuration of the Code Engine project includes the creation of the application , the IBM Cloud Container Registry access therefor it also creates a IBM Cloud API and it creates the secrets for the needed parameter for the running applications. It creates an IBM Cloud App ID instance and configures this instance that includes the application , redirects , login layout , scope , role and user . It also creates an IBM Cloud Postgres database instance and creates the needed example data with tables inside the database.","title":"Step 6: Understand the details of the initial installation bash scripts"},{"location":"getting-started/#step-7-verify-the-setup-by-using-following-url-httpscloudibmcomresources","text":"In resource list of the IBM Cloud UI, insert as filter for name the value multi . Now you should see following in your resource list:","title":"Step 7: Verify the setup by using following url https://cloud.ibm.com/resources"},{"location":"getting-started/#step-8-open-app-id-instance-for-tenant-a-and-inspect-the-configuration","text":"Open following URL https://cloud.ibm.com/resources","title":"Step 8: Open App ID instance for tenant a and inspect the configuration"},{"location":"getting-started/#step-9-open-code-engine-project-for-tenant-a-and-inspect-the-project","text":"Open following link in a browser: https://cloud.ibm.com/codeengine/projects","title":"Step 9: Open Code Engine project for tenant a and inspect the project"},{"location":"getting-started/#step-10-open-the-frontend-application-for-tenant-a-in-the-code-engine-project","text":"","title":"Step 10: Open the frontend application for tenant a in the Code Engine project"},{"location":"getting-started/#step-11-click-on-url-and-log-on-to-the-frontend-application-using-username-thomasexamplecom-and-password-thomas4appid","text":"","title":"Step 11: Click on URL and log on to the frontend application using username thomas@example.com and password thomas4appid"},{"location":"getting-started/#step-12-clean-up","text":"The clean-up reuses the configuration json files you defined for the setup/installatation. To delete all created resource you execute following commands: $ cd $ROOT_FOLDER /installapp $ ibmcloud login --sso $ sh ./ce-clean-up-two-tenancies.sh The table contains the script and the responsibility of the scripts. Script Responsibility ce-clean-up-two-tenancies.sh It starts the clean-up for the tenant application instances, therefor it invokes the bash script ce-clean-up.sh twice with the json configuration files as parameters. ce-clean-up.sh Deletes all created resouce for the two tenants.","title":"Step 12: Clean-up"},{"location":"k8s-onboarding/","text":"Onboarding \u00b6 ------------------ UNDER CONSTRUCTION ------------------ In this section we describe how to use the DevSecOps toolchains to onboard a new client. This will require adding a new tenant configuration file, using our scripts to provision a new instance of Postgres and AppId with service API keys, and triggering the CD pipeline after setting the environmental properties for the new tenant.","title":"K8s onboarding"},{"location":"k8s-onboarding/#onboarding","text":"------------------ UNDER CONSTRUCTION ------------------ In this section we describe how to use the DevSecOps toolchains to onboard a new client. This will require adding a new tenant configuration file, using our scripts to provision a new instance of Postgres and AppId with service API keys, and triggering the CD pipeline after setting the environmental properties for the new tenant.","title":"Onboarding"},{"location":"local-development/","text":"Develop Backend Service locally \u00b6 To run the backend service locally, a managed Postgres instance needs to be created first. After this you need to define four variables in local.env. See local.env.template for more: - POSTGRES_USERNAME - POSTGRES_PASSWORD - POSTGRES_URL - POSTGRES_CERTIFICATE_FILE_NAME Additionally you need to copy the certificate file in ./src/main/resources/certificates. As file name use the Postgres username. For the authentication a App ID instance is required. Copy the two settings in local.env: - APPID_CLIENT_ID (note: this is not the client id in the secrets, but in the application settings) - APPID_DISCOVERYENDPOINT For IBMers only: You can re-use existing services by using these configuration files. $ git clone https://github.com/IBM/multi-tenancy.git $ git clone https://github.com/IBM/multi-tenancy-backend.git $ git clone https://github.com/IBM/multi-tenancy-frontend.git $ cd multi-tenancy $ ROOT_FOLDER=$(pwd) $ cp certificate ${root_folder}/src/main/resources/certificates/ $ cp template.local.env local.env $ vi local.env Backend Run the backend service locally via Maven: $ sh ./scripts/run-locally-backend.sh Or run the backend service locally via container (podman): $ sh ./scripts/run-locally-container-backend.sh Invoke http://localhost:8081/category/2/products Frontend Run the frontend service locally: $ sh ./scripts/run-locally-frontend.sh Or run the frontend service locally via container (podman): $ sh ./scripts/run-locally-container-frontend.sh Invoke http://localhost:8080 User: thomas@example.com. Password: thomas4appid","title":"Develop Backend Service locally"},{"location":"local-development/#develop-backend-service-locally","text":"To run the backend service locally, a managed Postgres instance needs to be created first. After this you need to define four variables in local.env. See local.env.template for more: - POSTGRES_USERNAME - POSTGRES_PASSWORD - POSTGRES_URL - POSTGRES_CERTIFICATE_FILE_NAME Additionally you need to copy the certificate file in ./src/main/resources/certificates. As file name use the Postgres username. For the authentication a App ID instance is required. Copy the two settings in local.env: - APPID_CLIENT_ID (note: this is not the client id in the secrets, but in the application settings) - APPID_DISCOVERYENDPOINT For IBMers only: You can re-use existing services by using these configuration files. $ git clone https://github.com/IBM/multi-tenancy.git $ git clone https://github.com/IBM/multi-tenancy-backend.git $ git clone https://github.com/IBM/multi-tenancy-frontend.git $ cd multi-tenancy $ ROOT_FOLDER=$(pwd) $ cp certificate ${root_folder}/src/main/resources/certificates/ $ cp template.local.env local.env $ vi local.env Backend Run the backend service locally via Maven: $ sh ./scripts/run-locally-backend.sh Or run the backend service locally via container (podman): $ sh ./scripts/run-locally-container-backend.sh Invoke http://localhost:8081/category/2/products Frontend Run the frontend service locally: $ sh ./scripts/run-locally-frontend.sh Or run the frontend service locally via container (podman): $ sh ./scripts/run-locally-container-frontend.sh Invoke http://localhost:8080 User: thomas@example.com. Password: thomas4appid","title":"Develop Backend Service locally"},{"location":"observability/","text":"Observability (logging, monitoring, vulnerabilities) \u00b6 ------------------ UNDER CONSTRUCTION ------------------ Visibility of OpenShift and Kubernetes clusters on IBM Cloud can easily be enhanced by utilizing existing IBM Cloud services. In this section, we will: How IBM Log Analysis can be used to manage system and application logs. We will demonstrate how the sample application's logs can be filtered or searched, identifying logs on a per tenant basis for example. How IBM Cloud Monitoring can be used to gain operational visibility into the performance and health of the applications (e.g. the k8s deployments for each tenant), services (e.g. Postgres instances), and platforms (e.g. the health of the entire OpenShift or IBM Kubernetes Service cluster) How our sample DevSecOps toolchain uses DevOps Insights which can collect and analyze the results from unit tests, functional tests, and code coverage tools (using a variety of different sources). This provides visibility of quality, as policies at specified gates in the deployment process can be set, which can halt deployments preventing risks from being released. How our sample DevSecOps toolchain uses SonarCube to help ensure quality source code, how it can be configured, and how to resolve or whitelist issues. Explain how this relates or differs from Code Risk Analyzer . How our sample DevSecOps toolchain uses Continuous Delivery Vulnerability Advisor to help avoid container vulnerabilities, and how to resolve or whitelist the issues we encountered with our sample application.","title":"Observability"},{"location":"observability/#observability-logging-monitoring-vulnerabilities","text":"------------------ UNDER CONSTRUCTION ------------------ Visibility of OpenShift and Kubernetes clusters on IBM Cloud can easily be enhanced by utilizing existing IBM Cloud services. In this section, we will: How IBM Log Analysis can be used to manage system and application logs. We will demonstrate how the sample application's logs can be filtered or searched, identifying logs on a per tenant basis for example. How IBM Cloud Monitoring can be used to gain operational visibility into the performance and health of the applications (e.g. the k8s deployments for each tenant), services (e.g. Postgres instances), and platforms (e.g. the health of the entire OpenShift or IBM Kubernetes Service cluster) How our sample DevSecOps toolchain uses DevOps Insights which can collect and analyze the results from unit tests, functional tests, and code coverage tools (using a variety of different sources). This provides visibility of quality, as policies at specified gates in the deployment process can be set, which can halt deployments preventing risks from being released. How our sample DevSecOps toolchain uses SonarCube to help ensure quality source code, how it can be configured, and how to resolve or whitelist issues. Explain how this relates or differs from Code Risk Analyzer . How our sample DevSecOps toolchain uses Continuous Delivery Vulnerability Advisor to help avoid container vulnerabilities, and how to resolve or whitelist the issues we encountered with our sample application.","title":"Observability (logging, monitoring, vulnerabilities)"},{"location":"open_ibmcloud_shell/","text":"Lab 2: Open IBM Cloud Shell \u00b6 Step 1: Open the IBM Cloud Shell \u00b6 When using the IBM Cloud Shell, no client-side setup is required for this workshop, it comes with all necessary CLIs (command line tools). Use following link to directly open the IBM Cloud Shell . https://cloud.ibm.com/shell In your browser, login to the IBM Cloud Dashboard and open the IBM Cloud Shell from here: Note: Your workspace includes 500 MB of temporary storage. This session will close after an hour of inactivity. If you don't have any active sessions for an hour or you reach the 50-hour weekly usage limit, your workspace data is removed. Step 2: Verify IBM Cloud Shell \u00b6 Now you are logged on with your IBM Cloud account.","title":"2. Open IBM Cloud Shell"},{"location":"open_ibmcloud_shell/#lab-2-open-ibm-cloud-shell","text":"","title":"Lab 2: Open IBM Cloud Shell"},{"location":"open_ibmcloud_shell/#step-1-open-the-ibm-cloud-shell","text":"When using the IBM Cloud Shell, no client-side setup is required for this workshop, it comes with all necessary CLIs (command line tools). Use following link to directly open the IBM Cloud Shell . https://cloud.ibm.com/shell In your browser, login to the IBM Cloud Dashboard and open the IBM Cloud Shell from here: Note: Your workspace includes 500 MB of temporary storage. This session will close after an hour of inactivity. If you don't have any active sessions for an hour or you reach the 50-hour weekly usage limit, your workspace data is removed.","title":"Step 1: Open the IBM Cloud Shell"},{"location":"open_ibmcloud_shell/#step-2-verify-ibm-cloud-shell","text":"Now you are logged on with your IBM Cloud account.","title":"Step 2: Verify IBM Cloud Shell"},{"location":"security-and-compliance/","text":"Observability (logging, monitoring, vulnerabilities) \u00b6 ------------------ UNDER CONSTRUCTION ------------------ Provide a brief summary of how the IBM Security and Compliance Center is embedded into our DevSecOps toolchains, and how it can be used to achieve a continuously secure and compliant development environment. We will discuss collecting audit information and regulated workloads, and using automation to avoid catastrophic mistakes. This topics only applies to toolchains created from the DevSecOps templates.","title":"Security and compliance"},{"location":"security-and-compliance/#observability-logging-monitoring-vulnerabilities","text":"------------------ UNDER CONSTRUCTION ------------------ Provide a brief summary of how the IBM Security and Compliance Center is embedded into our DevSecOps toolchains, and how it can be used to achieve a continuously secure and compliant development environment. We will discuss collecting audit information and regulated workloads, and using automation to avoid catastrophic mistakes. This topics only applies to toolchains created from the DevSecOps templates.","title":"Observability (logging, monitoring, vulnerabilities)"},{"location":"serverless-cicd/","text":"Simple Pipelines to update Serverless Application \u00b6 In order to update the backend and frontend containers on Code Engine, simple CI/CD pipelines are provided. pipeline-backend: Builds the backend image and triggers the deployment pipelines for all tenants pipeline-backend-tenant: Deploys the backend container for one tenant pipeline-frontend: Builds the frontend image and triggers the deployment pipelines for all tenants pipeline-frontend-tenant: Deploys the frontend container for one tenant The pipelines will use the configuration from the configuration directory in which global and tenant specific settings need to be defined. When the IBM Toolchain with the four pipelines is created, the four github.com/IBM/multi-tenancy* repos are cloned to your GitLab user accounts on the IBM Cloud. The toolchain can be created simply by invoking this URL: https://cloud.ibm.com/devops/setup/deploy?repository=https://github.com/ibm/multi-tenancy-serverless-ci-cd Note that on the first page the region and the resource group need to be the same ones as defined in configuration/global.json . Leave all other default values. On the second page you only need to create an API key. Leave all other default values. After you've created the toolchain, change your configuration in the 'configuration' directory of your GitLab repo. Then you can invoke the first pipeline \"pipeline-backend\" manually. Once the image has been built, it will trigger the deployment pipelines. The \"pipeline-frontend\" pipeline will only work after the backend has been deployed since the frontend containers need to know the endpoints of the backend containers. Step by Step Instructions \u00b6 Step 1 Ensure that the two Postgres and AppID service instances have been created. Step 2 Clone or fork the three multi-tenancy* repos: https://github.com/IBM/multi-tenancy https://github.com/IBM/multi-tenancy-backend https://github.com/IBM/multi-tenancy-frontend Step 3 Configure your application in the following three files (replace IBM with your account): https://github.com/IBM/multi-tenancy/blob/main/configuration/global.json https://github.com/IBM/multi-tenancy/blob/main/configuration/tenants/tenant-a.json https://github.com/IBM/multi-tenancy/blob/main/configuration/tenants/tenant-b.json Step 4 The toolchain can be created simply by invoking this URL: https://cloud.ibm.com/devops/setup/deploy?repository=https://github.com/ibm/multi-tenancy-serverless-ci-cd Replace the links to the three repos with your repos. Leave all other defaults on the first page. Step 5 On the second page create an IBM Cloud API key. Step 6 Click 'create' to create the toolchain. As a result you'll see these repos and pipelines: Step 7 When triggered, the backend pipeline will execute these tasks: Read configuration from JSON files Build the backend image and push it to the IBM container registry For each tenant invoke the pipeline-backend-tenant pipeline Step 8 For each tenant containers are deployed to Code Engine: Read tenant specific configuration Deploy to Code Engine Step 9 The backend containers have been deployed to Code Engine. Step 10 The (unprotected) backend endpoint can now be invoked via '.../category/2/products'. Step 11 After the backend has been deployed, the frontend can be deployed. The frontend needs to know the endpoint of the backend. Repeat the steps above to build the frontend image. Step 12 After the frontend image has been built, the containers are deployed for different tenants. Step 13 Once deployed, the frontend can be launched. User: thomas@example.com, password: thomas4appid","title":"Simple Pipelines to update Serverless Application"},{"location":"serverless-cicd/#simple-pipelines-to-update-serverless-application","text":"In order to update the backend and frontend containers on Code Engine, simple CI/CD pipelines are provided. pipeline-backend: Builds the backend image and triggers the deployment pipelines for all tenants pipeline-backend-tenant: Deploys the backend container for one tenant pipeline-frontend: Builds the frontend image and triggers the deployment pipelines for all tenants pipeline-frontend-tenant: Deploys the frontend container for one tenant The pipelines will use the configuration from the configuration directory in which global and tenant specific settings need to be defined. When the IBM Toolchain with the four pipelines is created, the four github.com/IBM/multi-tenancy* repos are cloned to your GitLab user accounts on the IBM Cloud. The toolchain can be created simply by invoking this URL: https://cloud.ibm.com/devops/setup/deploy?repository=https://github.com/ibm/multi-tenancy-serverless-ci-cd Note that on the first page the region and the resource group need to be the same ones as defined in configuration/global.json . Leave all other default values. On the second page you only need to create an API key. Leave all other default values. After you've created the toolchain, change your configuration in the 'configuration' directory of your GitLab repo. Then you can invoke the first pipeline \"pipeline-backend\" manually. Once the image has been built, it will trigger the deployment pipelines. The \"pipeline-frontend\" pipeline will only work after the backend has been deployed since the frontend containers need to know the endpoints of the backend containers.","title":"Simple Pipelines to update Serverless Application"},{"location":"serverless-cicd/#step-by-step-instructions","text":"Step 1 Ensure that the two Postgres and AppID service instances have been created. Step 2 Clone or fork the three multi-tenancy* repos: https://github.com/IBM/multi-tenancy https://github.com/IBM/multi-tenancy-backend https://github.com/IBM/multi-tenancy-frontend Step 3 Configure your application in the following three files (replace IBM with your account): https://github.com/IBM/multi-tenancy/blob/main/configuration/global.json https://github.com/IBM/multi-tenancy/blob/main/configuration/tenants/tenant-a.json https://github.com/IBM/multi-tenancy/blob/main/configuration/tenants/tenant-b.json Step 4 The toolchain can be created simply by invoking this URL: https://cloud.ibm.com/devops/setup/deploy?repository=https://github.com/ibm/multi-tenancy-serverless-ci-cd Replace the links to the three repos with your repos. Leave all other defaults on the first page. Step 5 On the second page create an IBM Cloud API key. Step 6 Click 'create' to create the toolchain. As a result you'll see these repos and pipelines: Step 7 When triggered, the backend pipeline will execute these tasks: Read configuration from JSON files Build the backend image and push it to the IBM container registry For each tenant invoke the pipeline-backend-tenant pipeline Step 8 For each tenant containers are deployed to Code Engine: Read tenant specific configuration Deploy to Code Engine Step 9 The backend containers have been deployed to Code Engine. Step 10 The (unprotected) backend endpoint can now be invoked via '.../category/2/products'. Step 11 After the backend has been deployed, the frontend can be deployed. The frontend needs to know the endpoint of the backend. Repeat the steps above to build the frontend image. Step 12 After the frontend image has been built, the containers are deployed for different tenants. Step 13 Once deployed, the frontend can be launched. User: thomas@example.com, password: thomas4appid","title":"Step by Step Instructions"},{"location":"serverless_sprint_week_41_objectives/","text":"Objectives for sprint in week 41 serverless \u00b6 These are the main three objectives for this sprint. Running simple ecommerce application on Code Engine Automation of the deployment Documentation of the setup 1 Running simple ecommerce application on Code Engine \u00b6 App ID is configured (DONE) Frontend is integrated with AppID (DONE) Externalize configuration for Service Catalog (DONE) Externalize configuration for AppID (DONE) Backend is integrated with AppID (PENDING) Externalize configuration for AppID (PENDING) Backend is integrated postgres (IN PROGRESS) Externalize configuration for Postgress (IN PROGRESS) Postgres is setup (DONE) 2 Automation of the deployment \u00b6 Installation and setup is more about creation (IN PROGRESS) ( link to the bash script for initial creation ) CI/CD is more about update (IN PROGRESS) ( link to the Toolchain with the tekton pipeline ) 2.1 Differences between creation and update \u00b6 Creation ( link to the bash script for initial creation ) This is a simplified diagram containing the used elements and dependencies. Update ( link to the Toolchain with the tekton pipeline ) This is a simplified diagram containing the used elements and dependencies. 2.2 Used CLIs and APIs for the automation \u00b6 IBM Cloud Services IBM AppID REST API IBM Cloud CLI IBM Code Engine CLI IBM Cloud databases CLI IBM Cloud Container Registry CLI Bash automation Bash jq sed grep 3 Documentation of the setup \u00b6 Automation setup (in progress) Manual setup (pending) Workshop (pending)","title":"Objectives"},{"location":"serverless_sprint_week_41_objectives/#objectives-for-sprint-in-week-41-serverless","text":"These are the main three objectives for this sprint. Running simple ecommerce application on Code Engine Automation of the deployment Documentation of the setup","title":"Objectives for sprint in week 41 serverless"},{"location":"serverless_sprint_week_41_objectives/#1-running-simple-ecommerce-application-on-code-engine","text":"App ID is configured (DONE) Frontend is integrated with AppID (DONE) Externalize configuration for Service Catalog (DONE) Externalize configuration for AppID (DONE) Backend is integrated with AppID (PENDING) Externalize configuration for AppID (PENDING) Backend is integrated postgres (IN PROGRESS) Externalize configuration for Postgress (IN PROGRESS) Postgres is setup (DONE)","title":"1 Running simple ecommerce application on Code Engine"},{"location":"serverless_sprint_week_41_objectives/#2-automation-of-the-deployment","text":"Installation and setup is more about creation (IN PROGRESS) ( link to the bash script for initial creation ) CI/CD is more about update (IN PROGRESS) ( link to the Toolchain with the tekton pipeline )","title":"2  Automation of the deployment"},{"location":"serverless_sprint_week_41_objectives/#21-differences-between-creation-and-update","text":"Creation ( link to the bash script for initial creation ) This is a simplified diagram containing the used elements and dependencies. Update ( link to the Toolchain with the tekton pipeline ) This is a simplified diagram containing the used elements and dependencies.","title":"2.1 Differences between creation and update"},{"location":"serverless_sprint_week_41_objectives/#22-used-clis-and-apis-for-the-automation","text":"IBM Cloud Services IBM AppID REST API IBM Cloud CLI IBM Code Engine CLI IBM Cloud databases CLI IBM Cloud Container Registry CLI Bash automation Bash jq sed grep","title":"2.2 Used CLIs and APIs for the automation"},{"location":"serverless_sprint_week_41_objectives/#3-documentation-of-the-setup","text":"Automation setup (in progress) Manual setup (pending) Workshop (pending)","title":"3  Documentation of the setup"},{"location":"serverless_sprint_week_41_tasks/","text":"Tasks for sprint in week 41 serverless \u00b6 Table of tasks \u00b6 Project tasks/activities in ZenHub link Objectives Status Priority Notes 1 Running simple ecommerce application including Quarkus on Code Engine in progress high Running example: tenant b , tenant a 1.0 - Create a folder for the source code of the applications called code done high Inside the folder the name on the subfolders should refect the appliation name. 1.1 - AppID setup done high 1.2 - AppID integration to frontend done high 1.3 - AppID integration to Backend open high 1.4 - Backend database postgres integration done high 1.5 - Deploy to Code Engine in progress high the intergrated appid frontend and postgress backend is deployed 2 Automation of the deployment in progress high 2.0 - Define a folder structure for the installation/setup and CI/CD done high one folder call installapp (first time installation) cicd (continuous delivery realization with tekton) 2.1 - Create containers and save them in a public container registry open high 2.2 - Create a bash automation for the creation and configuration of AppID inprogress high Thomas need to copy the work he did the the project. 2.3 - Create a bash automation for the creation and configuration of postgres open high 2.4 - Create a bash automation for deployment to Code Engine in progress high 2.5 - Setup tekton using the IBM Cloud toolchain in progress high 2.6 - Integrate exiting bash automations to tekton pipeline open high 2.7 - Add an admin UI for onboarding of new tenant roberts application open low 2.7 - Problem to start the frontend container in code engine open high 3 Documenation of the setup open high We should use mkdocs 3.1 - Manual setup open high 3.2 - Automation setup open high 3.3 - Workshop open low","title":"Tasks"},{"location":"serverless_sprint_week_41_tasks/#tasks-for-sprint-in-week-41-serverless","text":"","title":"Tasks for sprint in week 41 serverless"},{"location":"serverless_sprint_week_41_tasks/#table-of-tasks","text":"Project tasks/activities in ZenHub link Objectives Status Priority Notes 1 Running simple ecommerce application including Quarkus on Code Engine in progress high Running example: tenant b , tenant a 1.0 - Create a folder for the source code of the applications called code done high Inside the folder the name on the subfolders should refect the appliation name. 1.1 - AppID setup done high 1.2 - AppID integration to frontend done high 1.3 - AppID integration to Backend open high 1.4 - Backend database postgres integration done high 1.5 - Deploy to Code Engine in progress high the intergrated appid frontend and postgress backend is deployed 2 Automation of the deployment in progress high 2.0 - Define a folder structure for the installation/setup and CI/CD done high one folder call installapp (first time installation) cicd (continuous delivery realization with tekton) 2.1 - Create containers and save them in a public container registry open high 2.2 - Create a bash automation for the creation and configuration of AppID inprogress high Thomas need to copy the work he did the the project. 2.3 - Create a bash automation for the creation and configuration of postgres open high 2.4 - Create a bash automation for deployment to Code Engine in progress high 2.5 - Setup tekton using the IBM Cloud toolchain in progress high 2.6 - Integrate exiting bash automations to tekton pipeline open high 2.7 - Add an admin UI for onboarding of new tenant roberts application open low 2.7 - Problem to start the frontend container in code engine open high 3 Documenation of the setup open high We should use mkdocs 3.1 - Manual setup open high 3.2 - Automation setup open high 3.3 - Workshop open low","title":"Table of tasks"},{"location":"setup_application/","text":"Lab 3: Setup e-commerce example application on IBM Cloud \u00b6 ------------------ UNDER CONSTRUCTION ------------------ Run automated first time installation setup \u00b6 Don't forget you need an IBM Cloud PayAsYouGo Account ! If you don't want to use the IBM Cloud Shell you need to install locally on your Mac: jq ( brew install jq ), IBM Cloud CLI , IBM Code Engine CLI - plugin and IBM Cloud databases CLI - plugin and IBM Cloud Container Registry CLI - plugin . Step 1: Clone the GitHub project to the IBM Cloud Shell \u00b6 Insert these commands to clone the GitHub project to the IBM Cloud Shell . git clone https://github.com/karimdeif/multi-tenancy.git cd multi-tenancy export ROOT_FOLDER = $( pwd ) Step 2: Inspect the default configuration of the setup bash scripts \u00b6 Prerequiste to run the bash scripts ( ce-create-two-tenantcies.sh and ce-install-application.sh for the setup: The container images for the applications need to be available.(in default uses Quay) Verify the default settings for the script execution. The ce-create-two-tenantcies.sh script has following default parameters for Code Engine , Applications , container registry , AppID and Postgres . Code Engine export PROJECT_NAME_A = multi-tenancy-serverless-a export PROJECT_NAME_B = multi-tenancy-serverless-b Applications export SERVICE_CATALOG_NAME_A = \"service-catalog-movies\" export FRONTEND_NAME_A = \"frontend-movies\" export SERVICE_CATALOG_NAME_B = \"service-catalog-fantasy\" export FRONTEND_NAME_B = \"frontend-fantasy\" export CATEGORY_A = Movies export CATEGORY_B = Fantasy IBM CLoud container registry export SERVICE_CATALOG_IMAGE = \"us.icr.io/multi-tenancy-cr/service-catalog:latest\" export FRONTEND_IMAGE = \"us.icr.io/multi-tenancy-cr/frontend:latest\" App ID export APPID_SERVICE_INSTANCE_NAME_A = \"multi-tenancy-serverless-appid-a\" export APPID_SERVICE_KEY_NAME_A = \"multi-tenancy-serverless-appid-key-a\" export APPID_SERVICE_INSTANCE_NAME_B = \"multi-tenancy-serverless-appid-b\" export APPID_SERVICE_KEY_NAME_B = \"multi-tenancy-serverless-appid-key-b\" Postgres export POSTGRES_SERVICE_INSTANCE_A = multi-tenant-pg-a export POSTGRES_SERVICE_INSTANCE_B = multi-tenant-pg-b Step 3: Execute following bash automation \u00b6 Don't worry, this script may take several minutes (10 - 15 min) without portgres. With postgres it will take up to 30 mins. Execute following bash script: cd $ROOT_FOLDER /installapp bash ce-create-two-tenantcies.sh What happens behind the curtain? The bash script ce-create-two-tenantcies.sh invokes twice the bash script ce-install-application.sh with the needed parameter to create two seperated tenant applications. Here is a short simplified description which steps are carried out currently in the script ce-install-application.sh : Configure IBM Cloud configuration for targets like $REGION and create an Code Engine CLI project Configure container the IBM Cloud container registry access in the Code Engine project Create Postgres instance and database Create an App ID service instance Configure the AppID service instance and use the App ID REST API to configure: application , scope , roles , users , login , logo and color . Create service catalog application in the Code Engine project Create frontend application in the Code Engine project Add redirect URI for the Frontend to AppID Verify Code Engine application deployments Show container logs of the applications Showing the URLs After the exection of the script you find your IBM Cloud account: Two App ID service instances which do include an user with the username thomas@example.com and password thomas4appid Two Code Engine projects with a fontend and a backend application and an configured access for the IBM Cloud container registry of your account. Note: We are using at the moment a preconfigured Postgres database running on IBM Cloud, which is maybe not in your cloud account. Verify the setup \u00b6 Step 1: Open following url https://cloud.ibm.com/resources \u00b6 In resource list of the IBM Cloud UI, insert as filter for name the value multi . Now you should see following in your resource list: Step 2: Open App ID instance for tenant a and inspect the configuration \u00b6 Open following URL https://cloud.ibm.com/resources Step 3: Open Code Engine project for tenant a and inspect the configuration \u00b6 Step 4: Open the frontend application for tenant a in the Code Engine project \u00b6 Step 5: Click on URL and logon to the frontend application using username thomas@example.com and password thomas4appid \u00b6 Step 6: Repeat the all steps for tenant b \u00b6 Optional Clean-up \u00b6 Step 1: Inspect the default configuration of the clean-up bash scripts \u00b6 Prerequiste to run the bash scripts ( ce-clean-up-two-tenantcies.sh and ce-clean-up.sh for the clean-up. These are the default values: Code Engine export PROJECT_NAME_A = multi-tenancy-serverless-tmp-a export PROJECT_NAME_B = multi-tenancy-serverless-tmp-b Applications export SERVICE_CATALOG_NAME_A = \"service-catalog-movies\" export FRONTEND_NAME_A = \"frontend-movies\" export SERVICE_CATALOG_NAME_B = \"service-catalog-fantasy\" export FRONTEND_NAME_B = \"frontend-fantasy\" App ID export APPID_SERVICE_INSTANCE_NAME_A = \"multi-tenancy-serverless-appid-a\" export APPID_SERVICE_KEY_NAME_A = \"multi-tenancy-serverless-appid-key-a\" export APPID_SERVICE_INSTANCE_NAME_B = \"multi-tenancy-serverless-appid-b\" export APPID_SERVICE_KEY_NAME_B = \"multi-tenancy-serverless-appid-key-b\" Postgres export POSTGRES_SERVICE_INSTANCE_A = \"multi-tenant-pg-a\" export POSTGRES_SERVICE_INSTANCE_B = \"multi-tenant-pg-b\" export POSTGRES_SERVICE_KEY_NAME_A = \"multi-tenant-pg-service-key-a\" export POSTGRES_SERVICE_KEY_NAME_B = \"multi-tenant-pg-service-key-b\" Step 2: Execute following bash automation in your IBM Cloud Shell \u00b6 Execute following bash script: cd $ROOT_FOLDER /installapp bash ce-clean-up-two-tenantcies.sh Step 3: Verify the App ID services are delete \u00b6 Open following URL https://cloud.ibm.com/resources Step 4: Verify the Code Engine projects are delete \u00b6 Open following URL https://cloud.ibm.com/codeengine/projects Step 4: Verify the IBM CLoud API key is deleted \u00b6 Open following URL https://cloud.ibm.com/iam/apikeys","title":"3. Setup e-commerce example application on IBM Cloud"},{"location":"setup_application/#lab-3-setup-e-commerce-example-application-on-ibm-cloud","text":"------------------ UNDER CONSTRUCTION ------------------","title":"Lab 3: Setup e-commerce example application on IBM Cloud"},{"location":"setup_application/#run-automated-first-time-installation-setup","text":"Don't forget you need an IBM Cloud PayAsYouGo Account ! If you don't want to use the IBM Cloud Shell you need to install locally on your Mac: jq ( brew install jq ), IBM Cloud CLI , IBM Code Engine CLI - plugin and IBM Cloud databases CLI - plugin and IBM Cloud Container Registry CLI - plugin .","title":"Run automated first time installation setup"},{"location":"setup_application/#step-1-clone-the-github-project-to-the-ibm-cloud-shell","text":"Insert these commands to clone the GitHub project to the IBM Cloud Shell . git clone https://github.com/karimdeif/multi-tenancy.git cd multi-tenancy export ROOT_FOLDER = $( pwd )","title":"Step 1: Clone the GitHub project to the IBM Cloud Shell"},{"location":"setup_application/#step-2-inspect-the-default-configuration-of-the-setup-bash-scripts","text":"Prerequiste to run the bash scripts ( ce-create-two-tenantcies.sh and ce-install-application.sh for the setup: The container images for the applications need to be available.(in default uses Quay) Verify the default settings for the script execution. The ce-create-two-tenantcies.sh script has following default parameters for Code Engine , Applications , container registry , AppID and Postgres . Code Engine export PROJECT_NAME_A = multi-tenancy-serverless-a export PROJECT_NAME_B = multi-tenancy-serverless-b Applications export SERVICE_CATALOG_NAME_A = \"service-catalog-movies\" export FRONTEND_NAME_A = \"frontend-movies\" export SERVICE_CATALOG_NAME_B = \"service-catalog-fantasy\" export FRONTEND_NAME_B = \"frontend-fantasy\" export CATEGORY_A = Movies export CATEGORY_B = Fantasy IBM CLoud container registry export SERVICE_CATALOG_IMAGE = \"us.icr.io/multi-tenancy-cr/service-catalog:latest\" export FRONTEND_IMAGE = \"us.icr.io/multi-tenancy-cr/frontend:latest\" App ID export APPID_SERVICE_INSTANCE_NAME_A = \"multi-tenancy-serverless-appid-a\" export APPID_SERVICE_KEY_NAME_A = \"multi-tenancy-serverless-appid-key-a\" export APPID_SERVICE_INSTANCE_NAME_B = \"multi-tenancy-serverless-appid-b\" export APPID_SERVICE_KEY_NAME_B = \"multi-tenancy-serverless-appid-key-b\" Postgres export POSTGRES_SERVICE_INSTANCE_A = multi-tenant-pg-a export POSTGRES_SERVICE_INSTANCE_B = multi-tenant-pg-b","title":"Step 2: Inspect the default configuration of the setup bash scripts"},{"location":"setup_application/#step-3-execute-following-bash-automation","text":"Don't worry, this script may take several minutes (10 - 15 min) without portgres. With postgres it will take up to 30 mins. Execute following bash script: cd $ROOT_FOLDER /installapp bash ce-create-two-tenantcies.sh What happens behind the curtain? The bash script ce-create-two-tenantcies.sh invokes twice the bash script ce-install-application.sh with the needed parameter to create two seperated tenant applications. Here is a short simplified description which steps are carried out currently in the script ce-install-application.sh : Configure IBM Cloud configuration for targets like $REGION and create an Code Engine CLI project Configure container the IBM Cloud container registry access in the Code Engine project Create Postgres instance and database Create an App ID service instance Configure the AppID service instance and use the App ID REST API to configure: application , scope , roles , users , login , logo and color . Create service catalog application in the Code Engine project Create frontend application in the Code Engine project Add redirect URI for the Frontend to AppID Verify Code Engine application deployments Show container logs of the applications Showing the URLs After the exection of the script you find your IBM Cloud account: Two App ID service instances which do include an user with the username thomas@example.com and password thomas4appid Two Code Engine projects with a fontend and a backend application and an configured access for the IBM Cloud container registry of your account. Note: We are using at the moment a preconfigured Postgres database running on IBM Cloud, which is maybe not in your cloud account.","title":"Step 3: Execute following bash automation"},{"location":"setup_application/#verify-the-setup","text":"","title":"Verify the setup"},{"location":"setup_application/#step-1-open-following-url-httpscloudibmcomresources","text":"In resource list of the IBM Cloud UI, insert as filter for name the value multi . Now you should see following in your resource list:","title":"Step 1: Open following url https://cloud.ibm.com/resources"},{"location":"setup_application/#step-2-open-app-id-instance-for-tenant-a-and-inspect-the-configuration","text":"Open following URL https://cloud.ibm.com/resources","title":"Step 2: Open App ID instance for tenant a and inspect the configuration"},{"location":"setup_application/#step-3-open-code-engine-project-for-tenant-a-and-inspect-the-configuration","text":"","title":"Step 3: Open Code Engine project for tenant a and inspect the configuration"},{"location":"setup_application/#step-4-open-the-frontend-application-for-tenant-a-in-the-code-engine-project","text":"","title":"Step 4: Open the frontend application for tenant a in the Code Engine project"},{"location":"setup_application/#step-5-click-on-url-and-logon-to-the-frontend-application-using-username-thomasexamplecom-and-password-thomas4appid","text":"","title":"Step 5: Click on URL and logon to the frontend application using username thomas@example.com and password thomas4appid"},{"location":"setup_application/#step-6-repeat-the-all-steps-for-tenant-b","text":"","title":"Step 6: Repeat the all steps for tenant b"},{"location":"setup_application/#optional-clean-up","text":"","title":"Optional Clean-up"},{"location":"setup_application/#step-1-inspect-the-default-configuration-of-the-clean-up-bash-scripts","text":"Prerequiste to run the bash scripts ( ce-clean-up-two-tenantcies.sh and ce-clean-up.sh for the clean-up. These are the default values: Code Engine export PROJECT_NAME_A = multi-tenancy-serverless-tmp-a export PROJECT_NAME_B = multi-tenancy-serverless-tmp-b Applications export SERVICE_CATALOG_NAME_A = \"service-catalog-movies\" export FRONTEND_NAME_A = \"frontend-movies\" export SERVICE_CATALOG_NAME_B = \"service-catalog-fantasy\" export FRONTEND_NAME_B = \"frontend-fantasy\" App ID export APPID_SERVICE_INSTANCE_NAME_A = \"multi-tenancy-serverless-appid-a\" export APPID_SERVICE_KEY_NAME_A = \"multi-tenancy-serverless-appid-key-a\" export APPID_SERVICE_INSTANCE_NAME_B = \"multi-tenancy-serverless-appid-b\" export APPID_SERVICE_KEY_NAME_B = \"multi-tenancy-serverless-appid-key-b\" Postgres export POSTGRES_SERVICE_INSTANCE_A = \"multi-tenant-pg-a\" export POSTGRES_SERVICE_INSTANCE_B = \"multi-tenant-pg-b\" export POSTGRES_SERVICE_KEY_NAME_A = \"multi-tenant-pg-service-key-a\" export POSTGRES_SERVICE_KEY_NAME_B = \"multi-tenant-pg-service-key-b\"","title":"Step 1: Inspect the default configuration of the clean-up bash scripts"},{"location":"setup_application/#step-2-execute-following-bash-automation-in-your-ibm-cloud-shell","text":"Execute following bash script: cd $ROOT_FOLDER /installapp bash ce-clean-up-two-tenantcies.sh","title":"Step 2: Execute following bash automation in your IBM Cloud Shell"},{"location":"setup_application/#step-3-verify-the-app-id-services-are-delete","text":"Open following URL https://cloud.ibm.com/resources","title":"Step 3: Verify the App ID services are delete"},{"location":"setup_application/#step-4-verify-the-code-engine-projects-are-delete","text":"Open following URL https://cloud.ibm.com/codeengine/projects","title":"Step 4: Verify the Code Engine projects are delete"},{"location":"setup_application/#step-4-verify-the-ibm-cloud-api-key-is-deleted","text":"Open following URL https://cloud.ibm.com/iam/apikeys","title":"Step 4: Verify the IBM CLoud API key is deleted"},{"location":"vue-appid-frontend/","text":"Using App ID in a Vue.js frontend \u00b6 Add App ID client SDK \u00b6 App ID client SDK for Single WebPage How to implement await in JavaScript Client SDK JavaScript npm install ibmcloud-appid-js To use refresh token, you need to enable refresh token, as you see in the image below. Use the App ID client SDK in Vue.js \u00b6 Relevant code in the main.js file. The code is structured in : Set variable for authentication Functions Login ( appID.Signin() ) Renew ( appID.silentSignin() ) App ID authentication init Create vue appilcation instance Renew token in an interval (https://www.unixtimestamp.com/index.php) import AppID from 'ibmcloud-appid-js' ; ... /**********************************/ /* Set variable for authentication /**********************************/ let appid_init ; let user_info ; /**********************************/ /* Functions /**********************************/ async function asyncAppIDInit ( appID ) { var appID_init_Result = await appID . init ( initOptions ); console . log ( \"--> log: appID_init_Result \" , appID_init_Result ); /**********************************/ /* Check if the user is already authenticated /**********************************/ if ( ! store . state . user . isAuthenticated ) { try { /******************************/ /* Authentication /******************************/ let tokens = await appID . signin (); console . log ( \"--> log: tokens \" , tokens ); user_info = { isAuthenticated : true , idToken : tokens . idToken , accessToken : tokens . accessToken , name : tokens . idTokenPayload . given_name } store . commit ( \"login\" , user_info ); return true ; } catch ( e ) { console . log ( \"--> log: error \" , e ); return false ; } } } async function asyncAppIDrefresh ( appID ) { if ( store . state . user . isAuthenticated == true ) { try { /******************************/ /* Authentication /******************************/ let tokens = await appID . silentSignin (); console . log ( \"--> log: silentSignin tokens \" , tokens ); user_info = { isAuthenticated : true , idToken : tokens . idToken , accessToken : tokens . accessToken // name : tokens.idTokenPayload.given_name } store . commit ( \"login\" , user_info ); return true ; } catch ( e ) { console . log ( \"--> log: catch interval error \" , e ); return false ; } } else { console . log ( \"--> log: no refresh \" ); return false ; } } /**********************************/ /* App ID authentication init /**********************************/ appid_init = { //web-app-tenant-a-single appid_clientId : window . VUE_APPID_CLIENT_ID , appid_discoveryEndpoint : window . VUE_APPID_DISCOVERYENDPOINT } console . log ( \"--> log: appid_init\" , appid_init ); store . commit ( \"setAppID\" , appid_init ); let initOptions = { clientId : store . state . appid_init . appid_clientId , discoveryEndpoint : store . state . appid_init . appid_discoveryEndpoint } /**********************************/ /* Create vue appication instance /**********************************/ let appID = new AppID (); let init_messsage = \"\" ; if ( ! ( init_messsage = asyncAppIDInit ( appID ))) { console . log ( \"--> log: init_messsage : \" + init_messsage ); window . location . reload (); } else { console . log ( \"--> log: init_messsage : \" + init_messsage ); // Vue application instance new Vue ({ store , router , render : h => h ( App ) }). $mount ( '#app' ) } /**********************************/ /* App ID authentication renew_token with silentSignin /**********************************/ let renew_token ; setInterval (() => { console . log ( \"--> log: token interval \" ); console . log ( \"--> log: isAuthenticated \" , store . state . user . isAuthenticated ); if ( store . state . user . isAuthenticated == false ) { renew_token = asyncAppIDrefresh ( appID ); console . log ( \"--> log: renew_token : \" + renew_token ); } else { console . log ( \"--> log: renew_token : \" + renew_token ); user_info = { isAuthenticated : false , idToken : \" \" , accessToken : \" \" , name : \" \" } store . commit ( \"login\" , user_info ); } }, 10000 );","title":"1. Using App ID in a Vue.js frontend"},{"location":"vue-appid-frontend/#using-app-id-in-a-vuejs-frontend","text":"","title":"Using App ID in a Vue.js frontend"},{"location":"vue-appid-frontend/#add-app-id-client-sdk","text":"App ID client SDK for Single WebPage How to implement await in JavaScript Client SDK JavaScript npm install ibmcloud-appid-js To use refresh token, you need to enable refresh token, as you see in the image below.","title":"Add App ID client SDK"},{"location":"vue-appid-frontend/#use-the-app-id-client-sdk-in-vuejs","text":"Relevant code in the main.js file. The code is structured in : Set variable for authentication Functions Login ( appID.Signin() ) Renew ( appID.silentSignin() ) App ID authentication init Create vue appilcation instance Renew token in an interval (https://www.unixtimestamp.com/index.php) import AppID from 'ibmcloud-appid-js' ; ... /**********************************/ /* Set variable for authentication /**********************************/ let appid_init ; let user_info ; /**********************************/ /* Functions /**********************************/ async function asyncAppIDInit ( appID ) { var appID_init_Result = await appID . init ( initOptions ); console . log ( \"--> log: appID_init_Result \" , appID_init_Result ); /**********************************/ /* Check if the user is already authenticated /**********************************/ if ( ! store . state . user . isAuthenticated ) { try { /******************************/ /* Authentication /******************************/ let tokens = await appID . signin (); console . log ( \"--> log: tokens \" , tokens ); user_info = { isAuthenticated : true , idToken : tokens . idToken , accessToken : tokens . accessToken , name : tokens . idTokenPayload . given_name } store . commit ( \"login\" , user_info ); return true ; } catch ( e ) { console . log ( \"--> log: error \" , e ); return false ; } } } async function asyncAppIDrefresh ( appID ) { if ( store . state . user . isAuthenticated == true ) { try { /******************************/ /* Authentication /******************************/ let tokens = await appID . silentSignin (); console . log ( \"--> log: silentSignin tokens \" , tokens ); user_info = { isAuthenticated : true , idToken : tokens . idToken , accessToken : tokens . accessToken // name : tokens.idTokenPayload.given_name } store . commit ( \"login\" , user_info ); return true ; } catch ( e ) { console . log ( \"--> log: catch interval error \" , e ); return false ; } } else { console . log ( \"--> log: no refresh \" ); return false ; } } /**********************************/ /* App ID authentication init /**********************************/ appid_init = { //web-app-tenant-a-single appid_clientId : window . VUE_APPID_CLIENT_ID , appid_discoveryEndpoint : window . VUE_APPID_DISCOVERYENDPOINT } console . log ( \"--> log: appid_init\" , appid_init ); store . commit ( \"setAppID\" , appid_init ); let initOptions = { clientId : store . state . appid_init . appid_clientId , discoveryEndpoint : store . state . appid_init . appid_discoveryEndpoint } /**********************************/ /* Create vue appication instance /**********************************/ let appID = new AppID (); let init_messsage = \"\" ; if ( ! ( init_messsage = asyncAppIDInit ( appID ))) { console . log ( \"--> log: init_messsage : \" + init_messsage ); window . location . reload (); } else { console . log ( \"--> log: init_messsage : \" + init_messsage ); // Vue application instance new Vue ({ store , router , render : h => h ( App ) }). $mount ( '#app' ) } /**********************************/ /* App ID authentication renew_token with silentSignin /**********************************/ let renew_token ; setInterval (() => { console . log ( \"--> log: token interval \" ); console . log ( \"--> log: isAuthenticated \" , store . state . user . isAuthenticated ); if ( store . state . user . isAuthenticated == false ) { renew_token = asyncAppIDrefresh ( appID ); console . log ( \"--> log: renew_token : \" + renew_token ); } else { console . log ( \"--> log: renew_token : \" + renew_token ); user_info = { isAuthenticated : false , idToken : \" \" , accessToken : \" \" , name : \" \" } store . commit ( \"login\" , user_info ); } }, 10000 );","title":"Use the App ID client SDK in Vue.js"},{"location":"vue-using-access-token-quarkus-endpoint/","text":"Vue.js using an accesstoken to invoke Quarkus endpoints \u00b6 Here is one example invokation: < md-menu md-size = \"small\" v-if = \"isAuthenticated == true\" > < md-button md-size = \"small\" md-menu-trigger style = \"color:white;\" > {{ getUserName() }} < md-icon class = \"md-size-x\" > verified_user </ md-icon ></ md-button > < md-menu-content > < md-menu-item v-on:click = \"onCheckTokenClicked()\" > Check token </ md-menu-item > < md-menu-item v-on:click = \"onLogoutClicked()\" > Logout </ md-menu-item > </ md-menu-content > </ md-menu > ... Using the REST endpoint of the articles service only on the local machine to verify the accesstoken usage in Quarkus. ... import axios from \"axios\" ; ... export default { name : \"app\" , components : { Catalog }, computed : { isAuthenticated () { return this . $store . state . user . isAuthenticated ; } }, ... methods : { onCheckTokenClicked (){ const axiosService = axios . create ({ timeout : 30000 , headers : { \"Content-Type\" : \"application/json\" , Authorization : \"Bearer \" + this . $store . state . user . accessToken } }); let that = this ; let url = \"http://localhost:8084/articlesA\" ; console . log ( \"--> log: readArticles URL : \" + url ); axiosService . get ( url ) . then ( function ( response ) { that . articles = response . data ; console . log ( \"--> log: readArticles data : \" + that . articles ); that . loading = false ; that . error = \"\" ; }) . catch ( function ( error ) { console . log ( \"--> log: readArticles error: \" + error ); that . loading = false ; that . error = error ; }); },","title":"2. Vue.js using accesstoken to invoke Quarkus endpoints"},{"location":"vue-using-access-token-quarkus-endpoint/#vuejs-using-an-accesstoken-to-invoke-quarkus-endpoints","text":"Here is one example invokation: < md-menu md-size = \"small\" v-if = \"isAuthenticated == true\" > < md-button md-size = \"small\" md-menu-trigger style = \"color:white;\" > {{ getUserName() }} < md-icon class = \"md-size-x\" > verified_user </ md-icon ></ md-button > < md-menu-content > < md-menu-item v-on:click = \"onCheckTokenClicked()\" > Check token </ md-menu-item > < md-menu-item v-on:click = \"onLogoutClicked()\" > Logout </ md-menu-item > </ md-menu-content > </ md-menu > ... Using the REST endpoint of the articles service only on the local machine to verify the accesstoken usage in Quarkus. ... import axios from \"axios\" ; ... export default { name : \"app\" , components : { Catalog }, computed : { isAuthenticated () { return this . $store . state . user . isAuthenticated ; } }, ... methods : { onCheckTokenClicked (){ const axiosService = axios . create ({ timeout : 30000 , headers : { \"Content-Type\" : \"application/json\" , Authorization : \"Bearer \" + this . $store . state . user . accessToken } }); let that = this ; let url = \"http://localhost:8084/articlesA\" ; console . log ( \"--> log: readArticles URL : \" + url ); axiosService . get ( url ) . then ( function ( response ) { that . articles = response . data ; console . log ( \"--> log: readArticles data : \" + that . articles ); that . loading = false ; that . error = \"\" ; }) . catch ( function ( error ) { console . log ( \"--> log: readArticles error: \" + error ); that . loading = false ; that . error = error ; }); },","title":"Vue.js using an accesstoken to invoke Quarkus endpoints"}]}